{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7262dc-6f95-4c11-a0b9-25dd489fddf8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c84999-d6ac-4842-b945-410078941bc2",
   "metadata": {
    "tags": [
     "remove-cell",
     "remove-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%run -i ../python/common.py\n",
    "publish=False\n",
    "\n",
    "if not publish:\n",
    "    # cleanup any old state\n",
    "    bashCmds('''[[ -d lec3 ]] && rm -rf mydir\n",
    "    [[ -a myinfo ]] && rm myinfo''')\n",
    "else:\n",
    "    bashCmds('''rm -rf ~/*''')\n",
    "    \n",
    "closeAllOpenTtySessions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125e110-8237-4f8f-8559-179e1607bba4",
   "metadata": {
    "hide_input": true,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "appdir=os.getenv('HOME')\n",
    "appdir=appdir + \"/parser\"\n",
    "TermShellCmd(\"ls \")\n",
    "output = runTermCmd(\"[[ -d \" + appdir + \" ]] &&  rm -rf \"+ appdir + \n",
    "             \";cp -r ../src/parser \" + appdir)\n",
    "bash = BashSession(cwd=appdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065caff0-f1d2-49ad-82f4-0e48dca6ef57",
   "metadata": {
    "tags": []
   },
   "source": [
    "(cont:gs:tools:testing)=\n",
    "# Testing\n",
    "\n",
    "Most students try to solve the complicated programs for this course by implementing them, and then manually testing their program.  This is, possible...., but incredibly challenging.  Proper unit and integration tests will, on the other hand, save you an enormous number of hours in this course. \n",
    "\n",
    "## Unit Tests\n",
    "\n",
    "As you develop your program, you are going to write many individual functions.  For each, think about how to write simple tests to see if the function does what you expect it to.  For example, one of the assignments we often hand out is a user level thread scheduler.  To get it to work, you need to set up the stack of the thread properly so that when the thread completes it calls a routine to exit. If you write a simple test at the beginning to test what happens after a thread completes, it will take a few minutes to identify and fix any bugs.  Many students, instead, spend hours trying to identify the problem manually when they have a running scheduler, with timer interrupts causing threads to switch between themselves.  \n",
    "\n",
    "Lets see some simple examples, we have already shown a script that runs a set of test programs ({numref}`run_tests`), and a makefile ({numref}`make_parser`)to invoke that script on a parser.  The first step on developing a parser is to define its interface, and a set of tests against that interface.  To do this, we define the data structures and functions that the parser will expose to its clients in a header file shown in {numref}`myshell_parser_h`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d0773-8838-46ec-b3e8-0e6b1a5bf7d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "% The block below creates a nice labeled Listing in the html, but not in the jupyter notebook view.\n",
    "```{literalinclude} /src/parser/myshell_parser.h\n",
    ":linenos:\n",
    ":language: make\n",
    ":caption: Header file for parser for shell\n",
    ":name: myshell_parser_h\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ca4b5-51ac-43c8-b535-7d6dee39dadc",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is removed in the html, but displays the code listing in the Jupyter notebook. \n",
    "file = appdir + \"/myshell_parser.h\"\n",
    "text_file = open(file, \"r\")\n",
    "data = text_file.read()\n",
    "data = numberLines(data)\n",
    "text_file.close()                                                                                             \n",
    "md_text = '''                                                                                                                        \n",
    "``` ''' + \"c\" + '''                                                                                                                     \n",
    "''' + data + '''                                                                                                                         \n",
    "```                                                                                                                                      \n",
    "'''\n",
    "display (Markdown(md_text))\n",
    "#display (Markdown('<font size=\".5rem\">' + md_text +'</font>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b58d06-5159-47d9-b3a5-1d1ce9d4666c",
   "metadata": {},
   "source": [
    "In this header file, we define everything that test programs, and eventually the shell will need to use to call the parser we will develop.  The routines `pipeline_build` returns a `pipeline` struct with a flag that indicates if the whole pipleline is in the background, and points to a linked list of `pipeline_commands`.   Each `pipeline_command` contains a boolean indicates if the command is in the background, and an array where the first element is the command and the other elements are arguments to that command. Our first implementation of `myshell_parser.c` (see {numref}`myshell_parser_c`) simply returns error messages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63523e3d-04d3-450c-be3b-7f75bce1ff00",
   "metadata": {
    "tags": []
   },
   "source": [
    "% The block below creates a nice labeled Listing in the html, but not in the jupyter notebook view.\n",
    "```{literalinclude} /src/parser/myshell_parser.c\n",
    ":linenos:\n",
    ":language: make\n",
    ":caption: Initial implementation of \n",
    ":name: myshell_parser_c\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755b1f2-a94f-4e51-88b1-0bf380732ac4",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is removed in the html, but displays the code listing in the Jupyter notebook. \n",
    "file = appdir + \"/myshell_parser.c\"\n",
    "text_file = open(file, \"r\")\n",
    "data = text_file.read()\n",
    "data = numberLines(data)\n",
    "text_file.close()                                                                                             \n",
    "md_text = '''                                                                                                                        \n",
    "``` ''' + \"c\" + '''                                                                                                                     \n",
    "''' + data + '''                                                                                                                         \n",
    "```                                                                                                                                      \n",
    "'''\n",
    "display (Markdown(md_text))\n",
    "#display (Markdown('<font size=\".5rem\">' + md_text +'</font>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642a20b-d78e-4630-9573-ad7fabddb704",
   "metadata": {},
   "source": [
    "Before implementing any functionality we write tests on what we expect a correct implementation to do.  For example, {numref}`test_simple_input_c` shows a test that calls the parser `pipeline_build` with a single command `ls`, asserts what it expects the state of a correct execution of the parser is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fefce-43c7-41b6-9f16-48f5dc738b39",
   "metadata": {
    "tags": []
   },
   "source": [
    "% The block below creates a nice labeled Listing in the html, but not in the jupyter notebook view.\n",
    "```{literalinclude} /src/parser/test_simple_input.c\n",
    ":linenos:\n",
    ":language: c\n",
    ":caption: Test of a simple \n",
    ":name: test_simple_input_c\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca36cec-23b8-4090-a8e2-681278a185c6",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is removed in the html, but displays the code listing in the Jupyter notebook. \n",
    "file = appdir + \"/test_simple_input.c\"\n",
    "text_file = open(file, \"r\")\n",
    "data = text_file.read()\n",
    "data = numberLines(data)\n",
    "text_file.close()                                                                                             \n",
    "md_text = '''                                                                                                                        \n",
    "``` ''' + \"c\" + '''                                                                                                                     \n",
    "''' + data + '''                                                                                                                         \n",
    "```                                                                                                                                      \n",
    "'''\n",
    "display (Markdown(md_text))\n",
    "#display (Markdown('<font size=\".5rem\">' + md_text +'</font>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c686c0c-93f5-436d-94c9-3b6f10f9db00",
   "metadata": {},
   "source": [
    "As another example, {numref}`test_pipe_input_c` runs a simple example of two commands with a pipe between them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15a273-b512-4375-b20e-83c887b194eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "% The block below creates a nice labeled Listing in the html, but not in the jupyter notebook view.\n",
    "```{literalinclude} /src/parser/test_simple_pipe.c\n",
    ":linenos:\n",
    ":language: c\n",
    ":caption: Test of a simple pipe\n",
    ":name: test_simple_pipe_c\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f7541-003a-4e11-ae27-aa8ec6d12b96",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is removed in the html, but displays the code listing in the Jupyter notebook. \n",
    "file = appdir + \"/test_simple_pipe.c\"\n",
    "text_file = open(file, \"r\")\n",
    "data = text_file.read()\n",
    "data = numberLines(data)\n",
    "text_file.close()                                                                                             \n",
    "md_text = '''                                                                                                                        \n",
    "``` ''' + \"c\" + '''                                                                                                                     \n",
    "''' + data + '''                                                                                                                         \n",
    "```                                                                                                                                      \n",
    "'''\n",
    "display (Markdown(md_text))\n",
    "#display (Markdown('<font size=\".5rem\">' + md_text +'</font>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f34a892-fe2c-4ec3-8220-5d843a607235",
   "metadata": {},
   "source": [
    "We have already provided examples of how you can invoke the unit test programs from a shell scripts ({numref}`run_tests`), and shown how that can in turn by automatically invoked by make ({numref}`make_parser`) so that every time you make a change the makefile will automatically re-run all the tests.  Now, given the above test files, if we type make with that makefile, the `all` rule will run the `check` rule which will recompile any required software and then invoke the shell script to run all the tests. In our case, both test programs assert because the pipeline returned is `NULL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b9ee9-5622-485a-9705-e271c89ad4e0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "bash.run(\"make clean ; make\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80b831-b5f7-4388-aa8f-ecda4e45b166",
   "metadata": {},
   "source": [
    "Unit tests are specific to the particular interfaces of the functions you write.  We expect students to write their own unit tests, since the internal functions of their application are up to them to design.  For the parser, we have defined the functions that we want you to implement, so that we can give you some example of unit tests.  However, we would recommend that a good parser implementation should start by implementing a lexer, that converts each syntactical element of the input into a set of tokens.  If you do that, you should add the new interface to the `.h` file and new tests to make sure that your lexing functionality works.\n",
    "\n",
    "You should never delete your tests.  For example, the parser will eventually become the first shell assignment for many courses based on this book.  You will keep adding new functionality, and as you do, you will find that you will find bugs in your parser.  If your makefile doesn't keep running all the old tests, you are very likely to be introducing bugs... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d93d6-5072-4c22-af13-6ee1620cd9b0",
   "metadata": {},
   "source": [
    "## Integration Tests\n",
    "\n",
    "Integration tests use the public interfaces end-to-end.  For example, the tests we run with gradescope to automatically test if your programs are correct are all integration tests.  We hope you will share your integration tests with the class, and in the BU version of the course, we will often add tests provided by students to the test suite we use in gradescope; the best way you can have tests you know you will pass is to contribute tests to us.  In many cases, you can write integration tests in the same we described above, but calling the public interfaces of libraries.  If the task is to develop a program, you can use, for example, shell scripts, with the output redirected to a file, to run tests, compare the result to an expect result, and raise an error if the results do not agree with the expected ones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae0926-14bc-40cf-9368-e24065cdb879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4e3c63a28d2eadc36e3bba0725a6dea388233dd4d06cf5319c6ed40df7370ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
