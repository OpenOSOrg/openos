{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44083773-7831-4c1f-ac34-3f9fa2e5b288",
   "metadata": {
    "tags": [
     "remove-output",
     "remove-cell",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%run -i ../python/common.py\n",
    "publish=False\n",
    "\n",
    "if not publish:\n",
    "    # cleanup any old state\n",
    "    # demke - fill in as we see what state gets generated in this page.\n",
    "    bashCmds('''[[ -d mydir ]] && rm -rf mydir\n",
    "    #''')\n",
    "else:\n",
    "    bashCmds('''rm -rf ~/*''')\n",
    "    \n",
    "closeAllOpenTtySessions()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3bc99-4c9f-41c8-8505-8011780d847e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "appdir=os.getenv('HOME')\n",
    "appdir=appdir + \"/sync\"\n",
    "output = runTermCmd(\"[[ -d \" + appdir + \" ]] &&  rm -rf \"+ appdir + \n",
    "             \";cp -r ../src/sync \" + appdir)\n",
    "\n",
    "bash = BashSession(cwd=appdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441ba8c-a814-4083-a3d4-df39a731d06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "(cont:sync:locks)=\n",
    "# Implementing Locks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603f0a8-93e2-4b81-a8f9-e299b31a85f2",
   "metadata": {},
   "source": [
    "\n",
    "Now let's try to implement the lock data type. In the following examples, we will use C/C++-like pseudo-code, rather than actual C, to make the key points more clearly. We will also consider the special case of two concurrent threads first, before the general case of N concurrent threads.\n",
    "\n",
    "(cont:sync:locks:interrupt_soln)=\n",
    "## The Oldest Trick in the Book - Disable Interrupts\n",
    "\n",
    "[Earlier]`(cont:sync:sharing:issues)`, we blamed interrupts for causing untimely context switches that allowed thread operations to be interleaved arbitrarily. So, if we disable interrupts in the `acquire()` function before the critical section, the currently executing thread cannot be kicked off the CPU until it enables interrupts in the `release()` function. Alas, this enticingly simple solution won't work in most cases. First, user-level processes are not allowed to disable interrupts, so this solution is only available to operating system code. Second, leaving interrupts disabled for a long period of time can cause other problems, so even in the OS, it can only be used for short critical sections that do not cause blocking. \n",
    "Third, we can't have different locks protecting different shared data objects if locks are implemented by disabling interrupts, since this approach will prevent other threads from running at all, regardless of what data they might want to access. Finally, and perhaps most importantly, disabling interrupts offers no protection against concurrent accesses from a thread running on another CPU, so this solution can only be applied on a uniprocessor. Historically, disabling interrupts was used to protect short critical sections in OS code, but in the multicore era, this idea has very limited uses.\n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:cs_interrupts\n",
    ":caption: Lock implementation using using interrupt disabling; C++-like definition.\n",
    "struct lock {\n",
    "\n",
    "    void acquire() {\n",
    "        disable_interrupts(); // cli on x86\n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        enable_interrupts(); // sti on x86\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "We now consider more general solutions that can be used in either user-level programs, or the operating system, without relying on any special hardware assistance. \n",
    "\n",
    "(cont:sync:locks:sw_solns)=\n",
    "## Lock Implementation Attempts with Ordinary Machine Instructions\n",
    "\n",
    "In this section, we will show you several attempts at implementing the lock functions that encapsulate the critical section entry and exit protocols. All of these solutions (or solution attempts) use only ordinary machine instructions (load, store, cmp, jmp, add, etc.). \n",
    "\n",
    "(cont:sync:locks:flag_soln)=\n",
    "### (Broken) Lock Implementation Attempt \\#1 - Check a Flag\n",
    "\n",
    "Suppose we introduce a shared boolean variable to check if the critical section is currently in use, as shown in {numref}`listing:sync:lockflag`. \n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:lockflag\n",
    ":caption: Lock implementation using a flag; C++-like definition.\n",
    "\n",
    "struct lock_s {\n",
    "    bool locked = false;\n",
    "    \n",
    "    void acquire() {\n",
    "        while(locked) { }; // empty loop body, just spins\n",
    "        locked = true;\n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        locked = false; \n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Each thread will check the `locked` flag repeatedly in the `while()` loop of the `acquire()` function until it finds the critical section is free. When a thread breaks out of the loop, it sets the `locked` flag to true, preventing other threads from accessing the critical section until it is done. On exit, it sets the `locked` flag to false again in the `release()` function so that another thread can enter. \n",
    "\n",
    "```{sidebar} This is called a *spinlock* because threads spin around the `while` loop until they can gain entry to the critical section. Since a thread keeps the CPU busy while it is waiting for entry, this spinning is called *busy waiting*.\n",
    "```\n",
    "\n",
    "Alas, this does not meet the mutual exclusion requirement. We have just replaced one race with another. Consider two concurrent threads, T0 and T1, attempting to enter their critical sections concurrently by calling `acquire()` on the same lock object. Each thread tests the value of `locked`, sees that is is `false`, and breaks out of their respective `while` loops. Both T0 and T1 then set `locked=true` and proceed to enter their critical sections concurrently.  The mutual exclusion requirement is violated, so we will have to try again. \n",
    "\n",
    "The heart of the problem with this non-solution is that our threads' operations can interleave so that the `locked` flag can change between the time when a thread tests if it is safe to proceed and the time when the thread sets the flag to prevent others from also entering the critical section. If we could make the TEST and the SET an indivisible atomic operation, this problem would go away. Indeed, today's processor architectures give us an instruction with the properties we need. But, the processors of the Djikstra's era did not, and it is instructive to consider how we can implement the critical section entry and exit protocols without special assistance from the hardware. We will then see how some hardware support simplifies matters considerably.\n",
    "\n",
    "(cont:sync:locks:turn_soln)=\n",
    "### (Broken) Sofware-only Lock Implementation Attempt \\#2 - Take Turns\n",
    "\n",
    "Let's try replacing the boolean `flag` with a `turn` variable to indicate which thread is allowed to use the critical section. Each thread will wait for `turn` to be set to its own thread id (tid) in the `acquire()` function before entering, and will set `turn` to the other thread's id in the `release()` function when it is done using the critical section, as shown in {numref}`listing:sync:lockturn`.\n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:lockturn\n",
    ":caption: Lock implementation for two threads using turns; C++-like definition.\n",
    "\n",
    "struct lock_s {\n",
    "    int turn = 0;\n",
    "    \n",
    "    void acquire() {\n",
    "        int me = getTid(); // which thread is running this function? Threads are numbered 0 or 1.\n",
    "        while(turn != me) { }; // empty loop body, just spins\n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        int me = getTid();\n",
    "        turn = 1 - me; // set turn to other thread (if me == 0, turn = 1; if me == 1, turn = 0)\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Does this meet our requirements? Let's examine them one by one. \n",
    "\n",
    "Mutual exclusion\n",
    " : The value of `turn` can only be 0 or 1 at any instant in time, and only the thread whose id matches `turn` is allowed entry to the critical section. So mutual exclusion is satisfied.\n",
    " \n",
    " Progress\n",
    "  : This requirement has two parts. The first part says that we can't delay the decision of which thread next gets to enter the critical section forever. That part is fine --- we decide on the next thread in the `release()` function by flipping the `turn` variable. The second part of the progress requirement says that threads in their *remainder* code can't delay threads that want to use the critical section, and here lies the problem. This solution requires a strict alternation of threads in the critical section. In {numref}`listing:sync:lockturn}` we initialized `turn` so that T0 must go first, but T0 and T1 could have different tasks and run at different relative speeds. If T1 reaches its critical section first, it is still blocked until T0 goes through its critical section and flips `turn` to 1. Similarly, if one thread has less work to do, and needs fewer trips through the critical section, it could leave the other thread waiting indefinitely for another turn. \n",
    "  \n",
    "Bounded waiting\n",
    " : Strangely, this does satisfy bounded waiting, since there is a bound on the number of times other threads can use the critical section after a thread has started the entry protocol (i.e., after a thread has invoked the `acquire()` function). Threads take turns, so T0 can use the critical section at most once after T1 calls the `acquire()` function and before T1 gains entry. It is irrelevant though because we don't have Progress. \n",
    " \n",
    "The issue with this \"solution\" is that a thread must wait its turn, even when the other thread has no interest in entering its critical section. \n",
    "\n",
    "We could go on for quite some time showing you attempts at solutions that do not quite work. In his classic 1965 paper on \"Cooperating Sequential Processes\" {cite}`10.5555/1102034`, Djikstra lays out several other broken alternatives and admits that \"people that had played with the problem started to doubt whether it could be solved at all.\" He gives credit to Dutch mathematication T. J. Dekker for coming up with the first correct solution for two threads (in 1959!). The main idea is to combine the notion of turns with an expression of interest from a thread when it wants to enter its critical section. You can read all about [Dekker's Algorithm]`https://en.wikipedia.org/wiki/Dekker%27s_algorithm` elsewhere, but suffice to say that it was fairly complex and doesn't generalize to more than two threads. \n",
    "A simpler solution that can generalize to more than 2 threads, built on the same ideas of combining turns with expressions of interest, was published by Gary L. Peterson in 1981 {cite}`Peterson1981`. \n",
    "\n",
    "(cont:sync:locks:peterson_soln)=\n",
    "### Software-only Lock Implementation Attempt \\#3 - Peterson's Algorithm\n",
    "\n",
    "The code for Peterson's Algorithm is shown in {numref}`listing:sync:lock_peterson`. We have added an array of boolean flags, `interested` where each thread can indicate its interest in entering its critical section, and initially both flags are set to `false`. Each thread will only write to its own `interested` flag, and read from the other thread's `interested` flag. To gain entry to its critical section, a thread first sets its `interested` flag to `true` so that the other thread can see that it wants to enter. Then, it will politely set the turn to the other thread, and busy wait until it sees that either the other thread is not interested, or the other thread has given back the turn. To leave the critical section, a thread simply sets its `interested` flag to false. \n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:lock_peterson\n",
    ":caption: Lock implementation for two threads using Peterson's Algorithm; C++-like definition.\n",
    "\n",
    "struct lock_s {\n",
    "    int turn = 0;\n",
    "    bool interested[2] = {false; false};\n",
    "    \n",
    "    void acquire() {\n",
    "        int me = getTid(); // which thread is running this function? Threads are numbered 0 or 1.\n",
    "        int other = 1 - me; // other thread's id\n",
    "        \n",
    "        interested[me] = true; // this thread wants to enter the critical section\n",
    "        turn = other;          // but is giving the other thread a chance to go first\n",
    "        while(interested[other] == true && turn == other) { }; // empty loop body, just spins\n",
    "        \n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        int me = getTid();\n",
    "        interested[me] = false;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's see if this solution meets all of our requirements.\n",
    "\n",
    "Mutual Exclusion\n",
    " : The combination of `interested` and `turn` variables ensure that only one thread can be in the critical section at a time. Suppose both T0 and T1 try to enter their critical sections at nearly the same time by calling `acquire()`. Both set their `interested` flags to `true`, so now both threads can see that the other thread is trying to enter. Now, both threads set `turn` to the other thread's id---either T0 setting `turn = 1` takes effect first and is overwritten by T1 setting `turn = 0`, or vice versa. Only one thread will be able to exit the `while` loop, because `turn` must be either 0 or 1. Suppose T0 is already in the critical section when T1 calls `acquire()`, then `interested[0] == true` and `turn == 1`, and T1 must wait in the `while` loop until `interested[0]` becomes `false`, which only happens when T0 leaves the critical section by calling `release()`.\n",
    " \n",
    "Progress\n",
    " : The second part of the progress requirement (threads in their *remainder* code do not delay threads that want to enter the critical section) is satisfied because the `interested` flag is false for any thread in the *remainder* code, and a thread can enter when `interested[other] == false`. The first part of the progress requirement (threads that want to enter can eventually do so) is satisfied because once a thread $T_i$ calls `acquire()` it will eventually return. There are only three possibilities. (1) if the other thread, $T_j$, is not interested in using the critical section, then `interested[other] == false` and $T_i$ can exit the `while` loop immediately and enter the critical section. (2) if the other thread, $T_j$, is already in its critical section, then `interested[other]` will eventually become `false` when $T_j$ leaves its critical section, and $T_i$ can exit its `while` loop and enter. (3) The other thread, $T_j$ is also requesting entry to its critical section, and must set `turn` to $T_i$ after setting its own interested flag; $T_i$ will exit its `while` loop because `turn == other` is now false, and $T_i$ can enter the critical section. \n",
    " \n",
    "Bounded Waiting\n",
    " : Once a thread $T_i$ has indicated interest in entering the critical section, the other thread $T_j$ can enter at most once before $T_i$\n",
    " is granted entry, because $T_j$ must set `turn` to $T_i$ when it tries to enter again.\n",
    " \n",
    "We have made an informal argument that Peterson's Algorithm satisfies the requirements. You should be skeptical of such arguments, because the history of synchronization teaches us that informal correctness arguments about concurrency are often wrong. The interested reader can find formal proofs of the correctness of Peterson's algorithm {cite}`Schneider1997`, or you can take our word for it.  \n",
    "\n",
    "### Discussion\n",
    "\n",
    "Over the years, *many* other algorithms were developed to solve the critical section problem, relying only on ordinary machine instructions. However, simpler solutions exist if we take advantage of special *atomic* machine instructions that are provided by all modern processor architectures. In addition, modern CPUs may re-order instructions on-the-fly during execution, and allow threads running on different CPUs to observe the effects of memory operations in different orders (this is called a *relaxed memory consistency model* but it can cause a lot of stress for programmers!). To make the solutions in this section work on modern hardware, additional instructions called *fences* have to be added to ensure correctness. We might as well use atomic instructions in the first place.\n",
    "\n",
    "## Atomic Instructions for Synchonization\n",
    "\n",
    "Recall that we ran into trouble with our first lock implementation in  {numref}`(cont:sync:locks:flag_soln)`, because threads could have their execution interrupted and interleaved with another thread also running the `acquire()` function between testing the `locked` flag and setting it to true. In this section we will look briefly at the semantics of some atomic machine instructions that can help us solve this problem.\n",
    "\n",
    "### Test-and-Set (TAS)\n",
    "\n",
    "Some CPU architectures provide an atomic `test-and-set` instruction with the behavior shown in {numref}`listing:sync:test-and-set`. Keep in mind that this code is just to show the effect of the test-and-set instruction --- it is really a single operation that executes atomically. \n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:test-and-set\n",
    ":caption: Semantics of the test-and-set atomic instruction.\n",
    "bool test-and-set(bool *location) \n",
    "{\n",
    "    bool old = *location;\n",
    "    if (old == false)\n",
    "        *location = true;    \n",
    "    return old;\n",
    "}\n",
    "```\n",
    "\n",
    "Notice that the value stored at `location` is always true after executing `test-and-set` --- either it was already true at the start, or it was initially false, the test succeeded, and it was set to true. By examining the old value, we can tell which case occurred. Actual implementations may make the test implicit and just unconditionally set `*location = true`, as shown in {numref}`listing:sync:test-and-set-opt`:\n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:test-and-set-opt\n",
    ":caption: Semantics of the test-and-set atomic instruction, alternate implementation.\n",
    "bool test-and-set(bool *location) \n",
    "{\n",
    "    bool old = *location;\n",
    "    *location = true;    \n",
    "    return old;\n",
    "}\n",
    "```\n",
    "\n",
    "Armed with a test-and-set instruction, implementing a lock is very easy. \n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:locktas\n",
    ":caption: Lock implementation using test-and-set; C++-like definition.\n",
    "struct lock {\n",
    "    bool locked = false;\n",
    "    \n",
    "    void acquire() {\n",
    "        while(test-and-set(&locked)) { }; // empty loop body, just spins\n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        locked = false; \n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "In the `acquire()` function, a thread will atomically check the state of the `locked` variable and set it to `true`. If the critical section is already in use by another thread, then `locked` will be `true` already, `test-and-set` will return `true` and the thread will stay in the `while` loop and try again. Eventually, the other thread will leave the critical section and call `release()`, setting `locked` to false. The next test-and-set will return `false` as the old value of `locked` (and will set `locked` to `true`), and the thread will leave the `while` loop and enter the critical section. But what if `locked` is `false` and two threads try to enter the critical section at the same time? Because test-and-set is atomic, one of the thread's will execute the instruction first and succeed in setting `locked` to `true`, while the other thread will fail and be forced to retry. \n",
    "\n",
    "### Compare-and-Swap (CAS)\n",
    "\n",
    "Another common atomic instruction is compare-and-swap, or CAS, which has the semantics shown in {numref}`listing:sync:cas`.\n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:cas\n",
    ":caption: Semantics of the compare-and-swap instruction.\n",
    "bool compare-and-swap(int *location, int expected, int newval) \n",
    "{\n",
    "    if (*location != expected) \n",
    "        return false;\n",
    "        \n",
    "    *location = newval;\n",
    "        return true;\n",
    "}\n",
    "```\n",
    "\n",
    "We can also implement locks using the compare-and-swap atomic operation.\n",
    "\n",
    "```{code-block} c\n",
    ":name: listing:sync:lockcas\n",
    ":caption: Lock implementation using compare-and-swap; C++-like definition.\n",
    "struct lock {\n",
    "    bool locked = false;\n",
    "    \n",
    "    void acquire() {\n",
    "        while(!compare-and-swap(&locked, false, true)) { }; // empty loop body, just spins\n",
    "    }\n",
    "\n",
    "    void release() {\n",
    "        locked = false; \n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "This is essentially the same as the version using test-and-set. A thread wanting to enter the critical section atomically compares the current value of `locked` to `false`. As long as the critical section is unavailable, this comparison will fail, compare-and-swap returns false, and the thread has to stay in the `while` loop trying again. \n",
    "\n",
    "### Discussion\n",
    "\n",
    "Different processor architectures provide different atomic instructions, making our lock implementations non-portable. However, the machine-dependent code can be hidden by library implementations. We also simplified the implementations that we showed you in {numref}`listing:sync:locktas` and {numref}`listing:sync:lockcas` by ignoring the need for fences in the `release()` function. And, we ignored the fact that C compilers can optimize accesses to plain variables, like `locked`, in ways that break correctness in the face of multi-threading. \n",
    "\n",
    "It wasn't until C11/C++11 that the C programming language got a memory consistency model and standard, language-level support for atomic operations. Now, it is possible to write portable versions of the lock functions, with the C compiler translating the atomic operations into the correct machine instructions for the target architecture. Here is a C11 implementation of a lock: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc7c72-6567-403b-8286-47b25abd3751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
